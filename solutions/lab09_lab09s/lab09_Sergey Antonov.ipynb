{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Зададим начальные настройки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создадим контекст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.3\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 50)\n",
    "spark.conf.set('spark.executor.cores', 4)\n",
    "sc.setCheckpointDir('checkpoint/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.history.kerberos.keytab', 'none'),\n",
       " ('spark.eventLog.enabled', 'true'),\n",
       " ('spark.dynamicAllocation.maxExecutors', '14'),\n",
       " ('spark.history.ui.port', '18081'),\n",
       " ('spark.driver.extraLibraryPath',\n",
       "  '/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64'),\n",
       " ('spark.history.fs.cleaner.interval', '7d'),\n",
       " ('spark.shuffle.io.serverThreads', '128'),\n",
       " ('spark.executor.extraLibraryPath',\n",
       "  '/usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64'),\n",
       " ('spark.serializer', 'org.apache.spark.serializer.KryoSerializer'),\n",
       " ('spark.driver.port', '39985'),\n",
       " ('spark.executorEnv.PYTHONPATH',\n",
       "  '{{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip'),\n",
       " ('spark.shuffle.file.buffer', '1m'),\n",
       " ('spark.sql.hive.convertMetastoreOrc', 'true'),\n",
       " ('spark.yarn.historyServer.address', 'master.cluster-lab.com:18081'),\n",
       " ('spark.sql.autoBroadcastJoinThreshold', '26214400'),\n",
       " ('spark.ui.filters',\n",
       "  'org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter'),\n",
       " ('spark.eventLog.dir', 'hdfs:///spark2-history/'),\n",
       " ('spark.sql.catalogImplementation', 'in-memory'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS',\n",
       "  'master.cluster-lab.com'),\n",
       " ('spark.sql.orc.impl', 'native'),\n",
       " ('spark.history.fs.logDirectory', 'hdfs:///spark2-history/'),\n",
       " ('spark.history.fs.cleaner.maxAge', '90d'),\n",
       " ('spark.sql.warehouse.dir', '/apps/spark/warehouse'),\n",
       " ('spark.sql.execution.arrow.enabled', 'true'),\n",
       " ('spark.kryoserializer.buffer.max', '512m'),\n",
       " ('spark.ui.proxyBase', '/proxy/application_1558598905289_0520'),\n",
       " ('spark.sql.statistics.fallBackToHdfs', 'true'),\n",
       " ('spark.yarn.archive', 'hdfs:///tmp/spark-archive.zip'),\n",
       " ('spark.dynamicAllocation.cachedExecutorIdleTimeout', '600s'),\n",
       " ('spark.history.provider',\n",
       "  'org.apache.spark.deploy.history.FsHistoryProvider'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'application_1558598905289_0520'),\n",
       " ('spark.driver.memory', '3G'),\n",
       " ('spark.sql.hive.metastore.jars',\n",
       "  '/usr/hdp/current/spark2-client/standalone-metastore/*'),\n",
       " ('spark.dynamicAllocation.executorIdleTimeout', '120s'),\n",
       " ('spark.deploy-mode', 'client'),\n",
       " ('spark.shuffle.service.enabled', 'true'),\n",
       " ('spark.yarn.queue', 'default'),\n",
       " ('spark.port.maxRetries', '50'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.history.fs.cleaner.enabled', 'true'),\n",
       " ('spark.executor.memory', '3G'),\n",
       " ('spark.master', 'yarn'),\n",
       " ('spark.driver.host', 'master.cluster-lab.com'),\n",
       " ('spark.io.compression.lz4.blockSize', '128kb'),\n",
       " ('spark.history.kerberos.principal', 'none'),\n",
       " ('spark.sql.orc.filterPushdown', 'true'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.shuffle.io.backLog', '8192'),\n",
       " ('spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES',\n",
       "  'http://master.cluster-lab.com:8088/proxy/application_1558598905289_0520'),\n",
       " ('spark.driver.maxResultSize', '2g'),\n",
       " ('spark.unsafe.sorter.spill.reader.buffer.size', '1m'),\n",
       " ('spark.dynamicAllocation.enabled', 'true'),\n",
       " ('spark.shuffle.unsafe.file.output.buffer', '5m'),\n",
       " ('spark.yarn.isPython', 'true'),\n",
       " ('spark.executor.cores', '1'),\n",
       " ('spark.driver.appUIAddress', 'http://master.cluster-lab.com:4042'),\n",
       " ('spark.executor.extraJavaOptions', '-XX:+UseNUMA'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.sql.hive.metastore.version', '3.0')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json,codecs\n",
    "import math\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import col, expr, when, desc,sum,count,udf,countDistinct\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем в DataFrame и подписываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data = '/labs/lab09data/'\n",
    "\n",
    "schema = StructType([StructField(str(i), j, True) for i,j in zip(('userId','movieId','rating'),(IntegerType(),IntegerType(),DoubleType()))])\n",
    "train = spark.read.csv(os.path.join(lab_data,'train.csv'),schema=schema,sep=\",\",header = True)\n",
    "\n",
    "#schema = StructType([StructField(str(i), j, True) for i,j in zip(('userId','movieId','tags'),(IntegerType(),IntegerType(),StringType()))])\n",
    "#tags = spark.read.csv(os.path.join(lab_data,'tags.csv'),schema=schema,sep=\",\",header = True)\n",
    "\n",
    "#schema = StructType([StructField(str(i), j, True) for i,j in zip(('movieId','title','genres'),(IntegerType(),StringType(),StringType()))])\n",
    "#movies = spark.read.csv(os.path.join(lab_data,'movies.csv'),schema=schema,sep=\",\",header = True)\n",
    "\n",
    "#schema = StructType([StructField(str(i), j, True) for i,j in zip(('movieId','imdbId','tmdbId'),(IntegerType(),StringType(),StringType()))])\n",
    "#links = spark.read.csv(os.path.join(lab_data,'links.csv'),schema=schema,sep=\",\",header = True)\n",
    "\n",
    "schema = StructType([StructField(str(i), j, True) for i,j in zip(('userId','movieId','rating'),(IntegerType(),IntegerType(),DoubleType()))])\n",
    "test = spark.read.csv(os.path.join(lab_data,'test.csv'),schema=schema,sep=\",\",header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем временные таблицы для обращения через SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.repartition(4).cache()\n",
    "#tags = tags.repartition(4).cache()\n",
    "#movies = movies.repartition(4).cache()\n",
    "#links = links.repartition(4).cache()\n",
    "test = test.repartition(4).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127374</td>\n",
       "      <td>11181</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>197777</td>\n",
       "      <td>13429</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122271</td>\n",
       "      <td>19058</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142930</td>\n",
       "      <td>11854</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>206377</td>\n",
       "      <td>21728</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0  127374    11181     4.0\n",
       "1  197777    13429     4.5\n",
       "2  122271    19058     5.0\n",
       "3  142930    11854     3.0\n",
       "4  206377    21728     3.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movies.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#links.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172982</td>\n",
       "      <td>19123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185782</td>\n",
       "      <td>5639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175982</td>\n",
       "      <td>24293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>168451</td>\n",
       "      <td>6203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221456</td>\n",
       "      <td>25894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0  172982    19123     0.0\n",
       "1  185782     5639     0.0\n",
       "2  175982    24293     0.0\n",
       "3  168451     6203     0.0\n",
       "4  221456    25894     0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=40, regParam=0.07, rank=50 , userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(train)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(als.maxIter, [20, 30, 40])\\\n",
    "                              .addGrid(als.rank, [50, 75, 100])\\\n",
    "                              .addGrid(als.regParam, [0.03, 0.05, 0.07])\\\n",
    "                              .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=als, estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator, numFolds=3, parallelism=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9216894199694399,\n",
       " 0.8651745398143187,\n",
       " 0.8435073569347568,\n",
       " 0.9264123317440429,\n",
       " 0.866988759794578,\n",
       " 0.8442870062876049,\n",
       " 0.9265173101969766,\n",
       " 0.867807067527653,\n",
       " 0.8450076412030472,\n",
       " 0.9053741122592653,\n",
       " 0.8554760904046129,\n",
       " 0.8381140200343042,\n",
       " 0.9075050084825871,\n",
       " 0.8559874304346491,\n",
       " 0.8385056773940537,\n",
       " 0.9062908877472091,\n",
       " 0.8559157266918556,\n",
       " 0.8387939616954758,\n",
       " 0.8968536754413168,\n",
       " 0.851383794898473,\n",
       " 0.8362002519212042,\n",
       " 0.8975834928749953,\n",
       " 0.8513727711530845,\n",
       " 0.8364791793543016,\n",
       " 0.8956230639743243,\n",
       " 0.850916346500108,\n",
       " 0.8366150334789586]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.bestModel.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cv_model.bestModel\n",
    "    ._java_obj     # Get Java object\n",
    "    .parent()      # Get parent (ALS estimator)\n",
    "    .getMaxIter()) # Get maxIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cv_model.bestModel\n",
    "    ._java_obj     # Get Java object\n",
    "    .parent()      # Get parent (ALS estimator)\n",
    "    .getRegParam()) # Get maxIter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cv_model.bestModel.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.422784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating\n",
       "0  3.422784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для начала посчитаем среднее для подстановки пропущенных результатов модели\n",
    "predictions.createOrReplaceTempView('predictions')\n",
    "avg = spark.sql('select avg(prediction) as rating from predictions where prediction !=\\'NaN\\'')\n",
    "avg.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропуски\n",
    "predictions.createOrReplaceTempView('predictions')\n",
    "test.createOrReplaceTempView('test')\n",
    "output = spark.sql('select t.userId,t.movieId, round (nvl(p.prediction,3.4),1) as rating \\\n",
    "                    from test t left join predictions p on p.userId=t.userId and p.movieId=t.movieId\\\n",
    "                    order by t.userId, t.movieId').coalesce(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2346</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5278</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9303</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11817</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1     1414     3.8\n",
       "1       1     2346     3.7\n",
       "2       1     5278     3.0\n",
       "3       1     9303     4.1\n",
       "4       1    11817     4.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " output.toPandas().to_csv('/data/home/sergey.antonov/lab09.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.toPandas().to_csv('/data/home/sergey.antonov/lab09s.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
