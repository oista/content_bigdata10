{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Демонстрация TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Math\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import nltk\n",
    "from nltk.text import TextCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем массив ```texts```, который содержит в себе 3 элемента - 3 'синтетических' текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [u'мама мама мама мыла рама',\n",
    "         u'рама это рама все просто',\n",
    "         u'очень просто']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Считаем частотность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без использования дополнительных библиотек посчитаем частотность каждого слова по всем текстам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number = {}\n",
    "for text in texts:\n",
    "    for word in text.split():\n",
    "        word_to_number[word] = word_to_number.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для красивой визуализации используем pandas, не обязательно, но наглядно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(word_to_number.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без использования дополнительных библиотек посчитаем частотность каждого слова по каждому тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number_for_each_texts = {}\n",
    "for text in texts:\n",
    "    word_to_number_for_each_texts[text] = {}\n",
    "    for word in text.split():\n",
    "        if word_to_number_for_each_texts[text].get(word):\n",
    "            word_to_number_for_each_texts[text][word] += 1\n",
    "        else:\n",
    "            word_to_number_for_each_texts[text][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_number_for_each_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для красивой визуализации использум pandas, не обязательно, но наглядно (в этот раз для красивой визуализации нужно заморочиться, но мы не будем заморачиваться)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(word_to_number_for_each_texts.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(word_to_number_for_each_texts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если слова нет в тексте, получаем NaN. Заменим такие значения нулями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(word_to_number_for_each_texts.values())).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь воспользуемся библиотекой ```sklearn```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "temp_matrix = count_vect.fit_transform(texts) # temp_matrix эта промежуточная матрица, понадобится в следующем кейсе,\n",
    "                                              # для вычисления tf-idf\n",
    "matrix_counts = temp_matrix.toarray()         # в данной матрице хранятся "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(temp_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(count_vect.vocabulary_.items()), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем красиво ```matrix_counts```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[0] for x in sorted(count_vect.vocabulary_.items(), key=lambda x: x[1])] # список слов, \n",
    "                                                                                   # чтобы сделать красивую шапку\n",
    "pd.DataFrame(matrix_counts, columns=words)  # при создании DataFrame передадим подготовленный список слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что такое TF-IDF?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF - term frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Просто частотность, что мы считали выше (https://en.wikipedia.org/wiki/Tf–idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'f_{t,d}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) TF по версии российской википедии (https://ru.wikipedia.org/wiki/TF-IDF) (!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\mathrm{tf}(t,d) = \\frac{f_{t,d}}{\\sum_k f_{t_k,d}}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Бинарная встречаемость. *0 - не было слова в тексте, 1 - было слово в тексте*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\mathrm{tf}(t,d) = \\left\\{ \\begin{matrix} 0, f_{t,d} = 0 \\\\ 1, f_{t,d} ≥ 1 \\end{matrix} \\right.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Логарифм от частоты +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\mathrm{tf}(t,d) = \\log(1 + f_{t,d})'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Нормированная частота (double normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'K + (1 - K) \\frac { f_{t,d} }{\\max({f_{t_i,d}})}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробности https://en.wikipedia.org/wiki/Tf–idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF - inverse document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 'Стандарт', логарифм отношения числа всех документов к числу документов, содержащих данное слово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\mathrm{idf}(t,D)=\\log\\frac{N}{|\\{d\\in D:t\\in d\\}|}\\\n",
    "             =\\log\\frac{|D|}{|(d_{i}\\supset t_{i})|}=\\log\\frac{N}{n_t}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Сглаженный IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\mathrm{idf}(t,D)=\\log(1+\\frac{N}{n_t})'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) IDF с использованием максимального значения DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\log\\left(1 + \\frac {\\max_t n_t} {n_t}\\right)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Вероятностная обратная встречаемость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Math(r'\\log\\frac {N - n_t} {n_t}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вычислим TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документация http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходный код https://github.com/scikit-learn/scikit-learn/blob/bb592f3865f02f1d6bf9dedce1a2554fa0ada800/sklearn/feature_extraction/text.py#L901"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "idf = (log(N/(n)+ 1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "matrix_tfidf = tfidf_transformer.fit_transform(temp_matrix).toarray()\n",
    "df_index = pd.DataFrame(matrix_tfidf, columns=words)\n",
    "df_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([tfidf_transformer.idf_]*3, columns=words)  # построим только ```idf```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поисковое ранжирование\n",
    "Ну посчитали мы tf-idf, что с ним делать теперь? Например, это можно использовать как значение релевантности в поиске"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "query = 'просто мама'\n",
    "q_words = nltk.word_tokenize(query, language='russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_index.loc[0][wrd] for wrd in q_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =[np.asarray([df_index.loc[i][wrd] for wrd in q_words]).sum() for i in range(len(df_index))]\n",
    "pd.DataFrame(data = np.asarray([texts, arr]).T, columns = ['text', 'rel']).sort_values(by='rel', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если база посерьезнее? Поищем что-нибудь про Родю Раскольникова :)\n",
    "Каждый абзац у нас будет считаться отдельным документом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dostoevsky.txt', encoding='cp1251') as f:\n",
    "    book = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "temp_matrix = count_vect.fit_transform(book) # temp_matrix эта промежуточная матрица, понадобится в следующем кейсе,\n",
    "                                              # для вычисления tf-idf\n",
    "matrix_counts = temp_matrix.toarray()         # в данной матрице хранятся \n",
    "matrix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_counts[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "matrix_tfidf = tfidf_transformer.fit_transform(temp_matrix.toarray()).toarray()\n",
    "words = [x[0] for x in sorted(count_vect.vocabulary_.items(), key=lambda x: x[1])] # список слов, \n",
    "\n",
    "df_index = pd.DataFrame(matrix_tfidf, columns=words)\n",
    "df_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ''\n",
    "q_words = nltk.word_tokenize(query.lower(), language='russian')\n",
    "q_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr =[np.asarray([df_index.loc[i][wrd] for wrd in q_words]).sum() for i in range(len(df_index))]\n",
    "result = pd.DataFrame(data = np.asarray([book, arr]).T, columns = ['text', 'rel']).sort_values(by='rel', ascending=False)\n",
    "\n",
    "#result['rel'] = result['rel'].apply(lambda x: float(x))\n",
    "result['rel'] = result['rel'].astype(float)\n",
    "result = result[result['rel'] > 0]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.iloc[0, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
